# CWord LLM Provider é…ç½®æŒ‡å— | LLM Provider Configuration Guide

## ğŸ“‹ ç›®å½• | Table of Contents

- [æ¶æ„è¯´æ˜](#æ¶æ„è¯´æ˜)
- [æ”¯æŒåˆ—è¡¨](#æ”¯æŒåˆ—è¡¨)
- [å¿«é€Ÿé…ç½®](#å¿«é€Ÿé…ç½®)
- [è¯¦ç»†é…ç½®](#è¯¦ç»†é…ç½®)
- [æµ‹è¯•è¿æ¥](#æµ‹è¯•è¿æ¥)
- [æ•…éšœæ’é™¤](#æ•…éšœæ’é™¤)
- [å¸¸è§é—®é¢˜](#å¸¸è§é—®é¢˜)

---

## ğŸ—ï¸ æ¶æ„è¯´æ˜ | Architecture

CWord ä½¿ç”¨**å¯æ’æ‹”çš„ LLM Provider æ¶æ„**ï¼Œæ”¯æŒå‡ ä¹æ‰€æœ‰ä¸»æµ LLM æœåŠ¡ï¼š

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         CWord Application               â”‚
â”‚  (Agents, Session, Coordinator)         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚         LLM Abstraction Layer           â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ Anthropic  â”‚  OpenAI  â”‚  Custom   â”‚  â”‚
â”‚  â”‚  Provider  â”‚ Provider â”‚  Provider â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚           â”‚           â”‚
        â–¼           â–¼           â–¼
    Claude       GPT-4      Any LLM
```

### è®¾è®¡åŸåˆ™

1. **æŠ½è±¡ä¼˜å…ˆ** - æ‰€æœ‰ LLM é€šè¿‡ç»Ÿä¸€æ¥å£è®¿é—®
2. **é…ç½®é©±åŠ¨** - é€šè¿‡ YAML é…ç½®åˆ‡æ¢ Provider
3. **å¼€æ”¾å…¼å®¹** - æ”¯æŒæ ‡å‡† OpenAI API åè®®
4. **æ˜“äºæ‰©å±•** - æ·»åŠ æ–° Provider åªéœ€ 3 æ­¥

---

## ğŸ“¦ æ”¯æŒåˆ—è¡¨ | Supported Providers

### âœ… åŸç”Ÿæ”¯æŒ (Native Support)

| Provider | ä»£ç  | çŠ¶æ€ | æ¨èæ¨¡å‹ | æ–‡æ¡£ |
|----------|------|------|----------|------|
| **Anthropic Claude** | `anthropic` | âœ… å®Œå…¨æ”¯æŒ | Claude 3.5 Sonnet | [é“¾æ¥](https://docs.anthropic.com/) |
| **OpenAI GPT** | `openai` | âœ… å®Œå…¨æ”¯æŒ | GPT-4, GPT-3.5 | [é“¾æ¥](https://platform.openai.com/docs) |

### ğŸ”Œ å…¼å®¹æ”¯æŒ (OpenAI-Compatible API)

#### ä¸­å›½å¤§é™†å‚å•† ğŸ‡¨ğŸ‡³

| Provider | ä»£ç  | æ¨¡å‹ç¤ºä¾‹ | Base URL |
|----------|------|----------|----------|
| **æ™ºè°±AI** | `openai` | chatglm3, chatglm-turbo | `https://open.bigmodel.cn/api/paas/v4/` |
| **ç™¾åº¦æ–‡å¿ƒåƒå¸†** | `openai` | ERNIE-Bot-4 | `https://aip.baidubce.com/rpc/2.0/ai_custom/v1/wenxinworkshop/` |
| **é˜¿é‡Œäº‘é€šä¹‰åƒé—®** | `openai` | qwen-turbo, qwen-plus | `https://dashscope.aliyuncs.com/compatible-mode/v1` |
| **è…¾è®¯äº‘æ··å…ƒ** | `openai` | hunyuan-lite | `https://api.hunyuan.cloud.tencent.com/v1` |
| **DeepSeek** | `openai` | deepseek-chat, deepseek-coder | `https://api.deepseek.com` |
| **æœˆä¹‹æš—é¢ Kimi** | `openai` | moonshot-v1-8k, moonshot-v1-32k | `https://api.moonshot.cn/v1` |
| **é›¶ä¸€ä¸‡ç‰© 01.AI** | `openai` | yi-34b-chat, yi-6b-chat | `https://api.lingyiwanwu.com/v1` |
| **MiniMax** | `openai` | abab6.5s-chat | `https://api.minimax.chat/v1` |

#### å›½é™…å‚å•† ğŸŒ

| Provider | ä»£ç  | æ¨¡å‹ç¤ºä¾‹ | Base URL |
|----------|------|----------|----------|
| **Azure OpenAI** | `openai` | gpt-4 | `https://your-resource.openai.azure.com/` |
| **Groq** | `openai` | llama2-70b-4096 | `https://api.groq.com/openai/v1` |
| **Cohere** | `openai` | command | `https://api.cohere.ai/v1` |
| **Together AI** | `openai` | llama-2-70b | `https://api.together.xyz/v1` |
| **Perplexity** | `openai` | sonar-medium | `https://api.perplexity.ai` |
| **Anyscale** | `openai` | meta-llama/Llama-2-70b | `https://api.endpoints.anyscale.com/v1` |

#### è‡ªéƒ¨ç½² & å¼€æº ğŸ 

| Provider | ä»£ç  | æ¨¡å‹ç¤ºä¾‹ | Base URL |
|----------|------|----------|----------|
| **Ollama** | `openai` | llama2, mistral | `http://localhost:11434/v1` |
| **LocalAI** | `openai` | Any GGUF model | `http://localhost:8080/v1` |
| **vLLM** | `openai` | Any model | `http://localhost:8000/v1` |
| **Text Generation WebUI** | `openai` | Any model | `http://localhost:5000/v1` |
| **LLM Studio** | `openai` | Any model | `http://localhost:10000/v1` |

---

## ğŸš€ å¿«é€Ÿé…ç½® | Quick Configuration

### æ–¹å¼ 1: Anthropic Claudeï¼ˆæ¨èï¼‰

```bash
# .env
ANTHROPIC_API_KEY=sk-ant-your-key-here
```

```yaml
# config/cword.yaml
default_model:
  provider: "anthropic"
  model: "claude-sonnet-4-5-20250929"
  temperature: 0.7
  max_tokens: 2000
```

### æ–¹å¼ 2: OpenAI GPT

```bash
# .env
OPENAI_API_KEY=sk-your-key-here
```

```yaml
# config/cword.yaml
default_model:
  provider: "openai"
  model: "gpt-4"
  temperature: 0.7
  max_tokens: 2000
```

### æ–¹å¼ 3: DeepSeekï¼ˆä¸­å›½ç”¨æˆ·æ¨èï¼‰

```bash
# .env
DEEPSEEK_API_KEY=your-deepseek-key
```

```yaml
# config/cword.yaml
default_model:
  provider: "openai"
  model: "deepseek-chat"
  base_url: "https://api.deepseek.com"
  api_key_env: "DEEPSEEK_API_KEY"
  temperature: 0.7
  max_tokens: 2000
```

### æ–¹å¼ 4: æœ¬åœ° Ollama

```yaml
# config/cword.yaml
default_model:
  provider: "openai"
  model: "llama2"
  base_url: "http://localhost:11434/v1"
  api_key: "not-needed"  # Ollama ä¸éœ€è¦ API key
  temperature: 0.7
  max_tokens: 2000
```

---

## ğŸ“– è¯¦ç»†é…ç½® | Detailed Configuration

### é…ç½®æ–‡ä»¶ä½ç½®

é…ç½®æ–‡ä»¶æŒ‰ä¼˜å…ˆçº§ä»é«˜åˆ°ä½ï¼š

1. `./config/cword.yaml` - é¡¹ç›®é…ç½®ï¼ˆæ¨èï¼‰
2. `~/.cword/config/cword.yaml` - ç”¨æˆ·é…ç½®
3. å†…ç½®é»˜è®¤é…ç½®

### å®Œæ•´é…ç½®ç¤ºä¾‹

```yaml
# config/cword.yaml

app:
  name: "CWord"
  version: "1.0.0"

# LLM é…ç½®
default_model:
  # Provider ç±»å‹: "anthropic" æˆ– "openai"
  provider: "openai"

  # æ¨¡å‹åç§°
  model: "deepseek-chat"

  # API ç«¯ç‚¹ï¼ˆå¯é€‰ï¼Œç”¨äºè‡ªå®šä¹‰ Providerï¼‰
  base_url: "https://api.deepseek.com"

  # API å¯†é’¥ç¯å¢ƒå˜é‡å
  api_key_env: "DEEPSEEK_API_KEY"

  # ç”Ÿæˆå‚æ•°
  temperature: 0.7        # 0.0-1.0ï¼Œè¶Šé«˜è¶Šéšæœº
  max_tokens: 2000        # æœ€å¤§ç”Ÿæˆ token æ•°
  timeout: 30             # è¯·æ±‚è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰

# å¯¹è¯é…ç½®
conversation:
  max_history: 50         # æœ€å¤§å†å²æ¶ˆæ¯æ•°
  summary_interval: 10    # æ¯Nè½®å¯¹è¯æ€»ç»“ä¸€æ¬¡
  auto_save_interval: 300 # è‡ªåŠ¨ä¿å­˜é—´éš”ï¼ˆç§’ï¼‰

# æ–‡æ¡£é…ç½®
documents:
  format: "markdown"
  include_decision_history: true
  include_conversation_summary: true
```

### ç¯å¢ƒå˜é‡é…ç½®

```bash
# .env

# Anthropic Claude
ANTHROPIC_API_KEY=sk-ant-xxx

# OpenAI
OPENAI_API_KEY=sk-xxx

# DeepSeek
DEEPSEEK_API_KEY=sk-xxx

# æ™ºè°±AI
ZHIPUAI_API_KEY=xxx

# é˜¿é‡Œäº‘
DASHSCOPE_API_KEY=sk-xxx

# ç™¾åº¦æ–‡å¿ƒ
BAIDU_API_KEY=xxx
BAIDU_SECRET_KEY=xxx

# è…¾è®¯æ··å…ƒ
TENCENT_SECRET_ID=xxx
TENCENT_SECRET_KEY=xxx

# æœˆä¹‹æš—é¢ Kimi
MOONSHOT_API_KEY=sk-xxx

# é›¶ä¸€ä¸‡ç‰©
YI_API_KEY=sk-xxx

# MiniMax
MINIMAX_API_KEY=xxx
MINIMAX_GROUP_ID=xxx

# Azure OpenAI
AZURE_OPENAI_API_KEY=xxx
AZURE_OPENAI_ENDPOINT=https://your-resource.openai.azure.com/
```

---

## ğŸ§ª æµ‹è¯•è¿æ¥ | Testing Connection

### æ–¹æ³• 1: ä½¿ç”¨ CWord å†…ç½®æµ‹è¯•

```bash
# å¯åŠ¨ CWord
python -m src.main

# è¾“å…¥æµ‹è¯•æ¶ˆæ¯
ğŸ’¬ è¯·å‘Šè¯‰æˆ‘æ‚¨æƒ³åšä»€ä¹ˆäº§å“ï¼Ÿ
> test

# å¦‚æœæ™ºèƒ½ä½“æ­£å¸¸å›å¤ï¼Œè¯´æ˜é…ç½®æˆåŠŸ
```

### æ–¹æ³• 2: ä½¿ç”¨ Python è„šæœ¬

```python
# test_llm.py
import asyncio
from src.llm.providers import create_llm_provider

async def test_provider():
    config = {
        "provider": "openai",
        "model": "deepseek-chat",
        "base_url": "https://api.deepseek.com",
        "api_key": "your-api-key"
    }

    llm = create_llm_provider(config)

    try:
        response = await llm.generate("Hello, this is a test!")
        print(f"âœ… è¿æ¥æˆåŠŸ! å“åº”: {response}")
    except Exception as e:
        print(f"âŒ è¿æ¥å¤±è´¥: {e}")

asyncio.run(test_provider())
```

è¿è¡Œæµ‹è¯•ï¼š
```bash
python test_llm.py
```

### æ–¹æ³• 3: ä½¿ç”¨ curl æµ‹è¯• API

```bash
# æµ‹è¯• DeepSeek
curl https://api.deepseek.com/v1/chat/completions \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer YOUR_API_KEY" \
  -d '{
    "model": "deepseek-chat",
    "messages": [{"role": "user", "content": "Hello"}]
  }'

# æµ‹è¯• Ollama
curl http://localhost:11434/v1/chat/completions \
  -H "Content-Type: application/json" \
  -d '{
    "model": "llama2",
    "messages": [{"role": "user", "content": "Hello"}]
  }'
```

---

## ğŸ”§ æ•…éšœæ’é™¤ | Troubleshooting

### é—®é¢˜ 1: API Key é”™è¯¯

**ç—‡çŠ¶**: `ValueError: API key not found`

**è§£å†³æ–¹æ¡ˆ**:
```bash
# æ£€æŸ¥ç¯å¢ƒå˜é‡
echo $OPENAI_API_KEY
echo $ANTHROPIC_API_KEY

# æˆ–æ£€æŸ¥ .env æ–‡ä»¶
cat .env

# ç¡®ä¿ç¯å¢ƒå˜é‡å·²å¯¼å‡º
export $(cat .env | xargs)
```

### é—®é¢˜ 2: ç½‘ç»œè¿æ¥å¤±è´¥

**ç—‡çŠ¶**: `RuntimeError: API error: Connection timeout`

**è§£å†³æ–¹æ¡ˆ**:
```yaml
# æ·»åŠ è¶…æ—¶é…ç½®
default_model:
  timeout: 60  # å¢åŠ è¶…æ—¶æ—¶é—´
  base_url: "https://api.example.com"  # æ£€æŸ¥ URL æ˜¯å¦æ­£ç¡®
```

### é—®é¢˜ 3: æ¨¡å‹ä¸å­˜åœ¨

**ç—‡çŠ¶**: `RuntimeError: Model not found`

**è§£å†³æ–¹æ¡ˆ**:
```yaml
# æ£€æŸ¥æ¨¡å‹åç§°æ˜¯å¦æ­£ç¡®
default_model:
  model: "correct-model-name"  # ç¡®è®¤æ¨¡å‹åç§°
```

### é—®é¢˜ 4: å›½å†…ç½‘ç»œè®¿é—® OpenAI/Anthropic

**è§£å†³æ–¹æ¡ˆ**: ä½¿ç”¨å›½å†…å‚å•†æˆ–ä»£ç†

```yaml
# é€‰é¡¹ 1: ä½¿ç”¨å›½å†…å‚å•†
default_model:
  provider: "openai"
  model: "deepseek-chat"
  base_url: "https://api.deepseek.com"

# é€‰é¡¹ 2: ä½¿ç”¨ä»£ç†
default_model:
  provider: "openai"
  base_url: "https://your-proxy.com/v1"
  api_key: "sk-xxx"
```

### é—®é¢˜ 5: è¿”å›ç»“æœä¸ºç©º

**ç—‡çŠ¶**: æ™ºèƒ½ä½“å“åº”ä¸ºç©ºæˆ–å¾ˆçŸ­

**è§£å†³æ–¹æ¡ˆ**:
```yaml
# å¢åŠ  max_tokens
default_model:
  max_tokens: 4000  # å¢åŠ æœ€å¤§ token æ•°

# è°ƒæ•´ temperature
default_model:
  temperature: 0.9  # æé«˜åˆ›é€ æ€§
```

---

## â“ å¸¸è§é—®é¢˜ | FAQ

### Q1: CWord æ”¯æŒå“ªäº› LLMï¼Ÿ

**A**: å‡ ä¹æ”¯æŒæ‰€æœ‰ä¸»æµ LLMï¼

- âœ… **å®˜æ–¹æ”¯æŒ**: Anthropic Claude, OpenAI GPTï¼ˆå¼€ç®±å³ç”¨ï¼‰
- âœ… **å…¼å®¹æ”¯æŒ**: ä»»ä½•æä¾› OpenAI å…¼å®¹ API çš„å‚å•†
- âœ… **å¯æ‰©å±•**: å¯ä»¥è½»æ¾æ·»åŠ è‡ªå®šä¹‰ Provider

å…³é”®é…ç½®å‚æ•°ï¼š
```yaml
provider: "openai"  # æˆ– "anthropic"
base_url: "https://your-provider.com"  # è‡ªå®šä¹‰ç«¯ç‚¹
```

### Q2: å¦‚ä½•é€‰æ‹©åˆé€‚çš„ Providerï¼Ÿ

**A**: æ ¹æ®éœ€æ±‚é€‰æ‹©ï¼š

| éœ€æ±‚ | æ¨è Provider | ç†ç”± |
|------|--------------|------|
| **æœ€ä½³è´¨é‡** | Claude 3.5 Sonnet / GPT-4 | æ¨ç†èƒ½åŠ›æœ€å¼º |
| **ä¸­å›½ç”¨æˆ·** | DeepSeek / Kimi | è®¿é—®ç¨³å®šï¼Œä¸­æ–‡å¥½ |
| **æ€§ä»·æ¯”** | Groq / DeepSeek | é€Ÿåº¦å¿«ã€ä»·æ ¼ä½ |
| **éšç§ä¿æŠ¤** | æœ¬åœ° Ollama | æ•°æ®ä¸ç¦»å¼€æœ¬åœ° |
| **ä¼ä¸šä½¿ç”¨** | Azure OpenAI | ä¼ä¸šçº§æ”¯æŒ |

### Q3: èƒ½å¦åŒæ—¶ä½¿ç”¨å¤šä¸ª Providerï¼Ÿ

**A**: å½“å‰ç‰ˆæœ¬ä½¿ç”¨å•ä¸€å…¨å±€ Providerï¼Œä½† v2.0 è®¡åˆ’æ”¯æŒï¼š
- ä¸åŒæ™ºèƒ½ä½“ä½¿ç”¨ä¸åŒ Provider
- è‡ªåŠ¨é€‰æ‹©æœ€ä¼˜ Provider
- Provider æ•…éšœè½¬ç§»

### Q4: å¦‚ä½•æ·»åŠ ä¸æ”¯æŒçš„ Providerï¼Ÿ

**A**: ä¸‰ç§æ–¹å¼ï¼š

**æ–¹å¼1**: ä½¿ç”¨ OpenAI å…¼å®¹æ¥å£ï¼ˆæ¨èï¼‰
```yaml
provider: "openai"
base_url: "https://new-provider.com/v1"
```

**æ–¹å¼2**: ä½¿ç”¨ä»£ç†æœåŠ¡
```yaml
provider: "openai"
base_url: "https://your-proxy.com/v1"
```

**æ–¹å¼3**: ç¼–å†™è‡ªå®šä¹‰ Providerï¼ˆé«˜çº§ï¼‰
```python
# src/llm/providers.py
class NewProvider(LLMProvider):
    async def generate(self, prompt: str, **kwargs) -> str:
        # å®ç°ä»£ç 
        pass
```

### Q5: æœ¬åœ° LLM æ€§èƒ½å¦‚ä½•ï¼Ÿ

**A**: å–å†³äºç¡¬ä»¶ï¼š

| ç¡¬ä»¶ | æ¨èæ¨¡å‹ | æ€§èƒ½ |
|------|---------|------|
| **M1/M2/M3 Mac** | Llama 2 7B/13B | â­â­â­â­ |
| **RTX 3060+** | Mistral 7B | â­â­â­â­ |
| **CPU Only** | Phi-2, TinyLlama | â­â­ |

å»ºè®®ï¼š
- Mac ç”¨æˆ·ä½¿ç”¨ Ollama + Mistral
- GPU ç”¨æˆ·ä½¿ç”¨ vLLM + Llama 2 13B
- CPU ç”¨æˆ·ä½¿ç”¨ LocalAI + Phi-2

### Q6: API è´¹ç”¨å¦‚ä½•ï¼Ÿ

**A**: å‚è€ƒä»·æ ¼ï¼ˆæ¯ 1M tokensï¼‰ï¼š

| Provider | è¾“å…¥ | è¾“å‡º |
|----------|------|------|
| Claude 3.5 Sonnet | $3 | $15 |
| GPT-4 | $30 | $60 |
| GPT-3.5 Turbo | $0.5 | $1.5 |
| DeepSeek | Â¥1 | Â¥2 |
| Kimi | Â¥0.012 | Â¥0.012 |
| æœ¬åœ° LLM | å…è´¹ | å…è´¹ |

**ä¼°ç®—**: å…¸å‹å¯¹è¯ï¼ˆçº¦ 2000 tokensï¼‰ï¼š
- Claude: ~$0.03
- GPT-4: ~$0.12
- DeepSeek: ~Â¥0.002
- æœ¬åœ°: å…è´¹

### Q7: å¦‚ä½•ä¼˜åŒ–å“åº”é€Ÿåº¦ï¼Ÿ

**A**:

1. **é€‰æ‹©å¿«é€Ÿçš„ Provider**
   ```yaml
   provider: "openai"
   model: "deepseek-chat"  # å¾ˆå¿«
   ```

2. **å‡å°‘ max_tokens**
   ```yaml
   max_tokens: 1000  # è€Œä¸æ˜¯ 2000
   ```

3. **ä½¿ç”¨æœ¬åœ° LLM**
   ```yaml
   provider: "openai"
   base_url: "http://localhost:11434/v1"
   ```

4. **ä¼˜åŒ–ç½‘ç»œ**
   - ä½¿ç”¨åœ°ç†ä½ç½®è¿‘çš„ Provider
   - ä½¿ç”¨ä»£ç†åŠ é€Ÿ

### Q8: æ•°æ®éšç§å¦‚ä½•ä¿éšœï¼Ÿ

**A**:

**ä½¿ç”¨äº‘ç«¯ API**:
- æ•°æ®å‘é€åˆ° Provider æœåŠ¡å™¨
- éœ€éµå®ˆ Provider çš„éšç§æ”¿ç­–
- å»ºè®®ï¼šé¿å…æ•æ„Ÿæ•°æ®

**ä½¿ç”¨æœ¬åœ° LLM**:
- æ•°æ®ä¸ç¦»å¼€æœ¬åœ°
- å®Œå…¨éšç§ä¿æŠ¤
- æ¨èï¼šOllama + LocalAI

---

## ğŸ“š æ›´å¤šèµ„æº

### å®˜æ–¹æ–‡æ¡£

- [Anthropic Claude æ–‡æ¡£](https://docs.anthropic.com/)
- [OpenAI API æ–‡æ¡£](https://platform.openai.com/docs)
- [DeepSeek æ–‡æ¡£](https://platform.deepseek.com/docs)
- [Ollama æ–‡æ¡£](https://github.com/ollama/ollama)

### ç¤¾åŒºèµ„æº

- [CWord GitHub](https://github.com/yourusername/cword)
- [Issues](https://github.com/yourusername/cword/issues)
- [Discussions](https://github.com/yourusername/cword/discussions)

---

## ğŸ¯ æ€»ç»“

### å…³é”®è¦ç‚¹

1. âœ… **æ”¯æŒå¹¿æ³›** - å‡ ä¹æ‰€æœ‰ä¸»æµ LLM
2. ğŸ”§ **é…ç½®ç®€å•** - ä¿®æ”¹ YAML å³å¯
3. ğŸŒ **å›½å†…å‹å¥½** - å¤šä¸ªå›½å†…å‚å•†æ”¯æŒ
4. ğŸ  **æœ¬åœ°éƒ¨ç½²** - æ”¯æŒç¦»çº¿ä½¿ç”¨
5. ğŸš€ **æ˜“äºæ‰©å±•** - æ·»åŠ æ–° Provider å¾ˆç®€å•

### æ¨èé…ç½®

**å›½å¤–ç”¨æˆ·**:
```yaml
provider: "anthropic"
model: "claude-sonnet-4-5-20250929"
```

**å›½å†…ç”¨æˆ·**:
```yaml
provider: "openai"
model: "deepseek-chat"
base_url: "https://api.deepseek.com"
```

**ä¼ä¸š/éšç§**:
```yaml
provider: "openai"
base_url: "http://your-internal-llm/v1"
```

---

**æ–‡æ¡£ç‰ˆæœ¬**: 1.0.0
**æœ€åæ›´æ–°**: 2026-02-04
**ç»´æŠ¤è€…**: CWord Team
